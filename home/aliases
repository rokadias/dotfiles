alias gbds='git checkout -q $(git_main_branch) && git for-each-ref refs/heads/ "--format=%(refname:short)" | while read branch; do mergeBase=$(git merge-base $(git_main_branch) $branch) && [[ $(git cherry $(git_main_branch) $(git commit-tree $(git rev-parse $branch\^{tree}) -p $mergeBase -m _)) == "-"* ]] && git branch -D $branch; done'
alias gbc="git branch --sort=-committerdate | grep sr/"

export GH_JSON_FIELDS="assignees,author,reviewDecision,number,url,title,headRefName"
export GH_COLUMN_FIELDS="ASSIGNEE,AUTHOR,REVIEW STATUS,number,URL,TITLE,BRANCH"
export GH_JQ='.[] | [.assignees[].login //"unassigned", .author.login, .reviewDecision, .number, .url, .title, .headRefName] | @csv'

alias gh-pr-all="gh pr list  --json $GH_JSON_FIELDS --jq '$GH_JQ' | grep -v dependabot | column -t -s, -N \"$GH_COLUMN_FIELDS\" -T TITLE -n 'All PRs'"
alias gh-pr-me="gh pr list --assignee @me  --json $GH_JSON_FIELDS --jq '$GH_JQ' | grep -v dependabot | column -t -s, -N \"$GH_COLUMN_FIELDS\" -T TITLE -n 'Needs Review'"
alias gh-pr-my="gh pr list --author @me  --json $GH_JSON_FIELDS --jq '$GH_JQ' | grep -v dependabot | column -t -s, -N \"$GH_COLUMN_FIELDS\" -T TITLE -n 'Needs Review'"

function watchLatestMainBuild {
    local WORKFLOW_NAME=$1
    local SecondFilter=$2
    JOBS=$(gh run list -w "$WORKFLOW_NAME" | grep "\(main\)\|\(master\)")
    if [[ -n $SecondFilter ]]; then
        JOBS=$(echo -n "$JOBS" | grep "$SecondFilter")
    fi
    echo $JOBS | column -t -s$'\t' -T 3
    JOB=$(echo -n "$JOBS" | head -n 1)
    NAME=$(echo -n "$JOB" | cut -f 3)
    JOB_ID=$(echo -n "$JOB" | sed -e 's/.*\([0-9]\{10\}\).*/\1/')
    notify-send "Watching on main: $NAME"
    echo "Found Workflow Job Id: $JOB_ID"
    gh run watch $JOB_ID  && RETURN_CODE=$? || RETURN_CODE=$?
    if [[ $RETURN_CODE -eq 0 ]]; then
        notify-send "$WORKFLOW_NAME Done :-)"
    else
        notify-send "Oh no $WORKFLOW_NAME Failed !!"
        exit 1
    fi
}

alias gh-watch-main="watchLatestMainBuild"

function watchWorkflow {
    local WORKFLOW_NAME=$1
    JOB=$(gh run list -w "$WORKFLOW_NAME" -L 1)
    NAME=$(echo -n "$JOB" | cut -f 3)
    JOB_ID=$(echo -n "$JOB" | sed -e 's/.*\([0-9]\{10\}\).*/\1/')
    notify-send "Watching latest build: $NAME"
    echo "Found Workflow Job Id: $JOB_ID"
    gh run watch --exit-status $JOB_ID && RETURN_CODE=$? || RETURN_CODE=$?
    if [[ $RETURN_CODE -eq 0 ]]; then
        notify-send "$WORKFLOW_NAME Done :-)"
    else
        notify-send "Oh no $WORKFLOW_NAME Failed !!"
        exit 1
    fi
}

alias gh-watch-workflow="watchWorkflow"

function runAndWatchWorkflow {
    local WORKFLOW_NAME=$1
    gh workflow run "$WORKFLOW_NAME"
    echo "Sleep for 20 seconds to make sure that github triggers the $WORKFLOW_NAME workflow"
    sleep 20
    watchWorkflow "$WORKFLOW_NAME"
}

alias gh-run-and-watch-workflow="runAndWatchWorkflow"

function viewFailedPRJobLogs {
    local WORKFLOW_NAME=$1
    JOB=$(gh run list -w "$WORKFLOW_NAME" -b $(git rev-parse --abbrev-ref HEAD) -L 1)
    NAME=$(echo -n "$JOB" | cut -f 3)
    JOB_ID=$(echo -n "$JOB" | sed -e 's/.*\([0-9]\{10\}\).*/\1/')
    FAILED_RUNS=$(gh run view -q '.jobs | map(select(.conclusion == "failure"))' --json 'jobs' $JOB_ID)
    FAILED_RUN_IDS=$(echo -n "$FAILED_RUNS" | jq '.[].databaseId')
    REMOTE_REPO=$(g remote get-url origin | sed -e 's!\(ssh://\|https://\)github.com/!!' -e 's/\.git//')
    for FAIL_RUN_ID in $(echo -n "$FAILED_RUN_IDS" | sed -e 's/\n/ /g')
    do
        FAILED_RUN_NAME=$(echo -n "$FAILED_RUNS" | jq "map(select(.databaseId == $FAIL_RUN_ID)) | .[0].name")
        echo
        echo "Viewing Failed Job Run for '$FAILED_RUN_NAME'"
        echo
        PAGER="" gh api /repos/${REMOTE_REPO}/actions/jobs/${FAIL_RUN_ID}/logs
    done
}

alias gh-pr-fl="viewFailedPRJobLogs"

function viewPushedPRJobLogs {
    local WORKFLOW_NAME=$1
    JOB=$(gh run list -w "$WORKFLOW_NAME" -b $(git rev-parse --abbrev-ref HEAD) -L 1)
    NAME=$(echo -n "$JOB" | cut -f 3)
    JOB_ID=$(echo -n "$JOB" | sed -e 's/.*\([0-9]\{10\}\).*/\1/')
    PUSHED_JOBS_RUNS=$(gh run view -q '.jobs | map(select(.name == "Python Docker Build and ECR Push" or .name == "Frontend Docker Build and ECR Push"))' --json 'jobs' $JOB_ID)
    PUSHED_JOBS_RUN_IDS=$(echo -n "$PUSHED_JOBS_RUNS" | jq '.[].databaseId')
    REMOTE_REPO=$(g remote get-url origin | sed -e 's!\(ssh://\|https://\)github.com/!!' -e 's/\.git//')
    for PUSHED_JOBS_RUN_ID in $(echo -n "$PUSHED_JOBS_RUN_IDS" | sed -e 's/\n/ /g')
    do
        FAILED_RUN_NAME=$(echo -n "$PUSHED_JOBS_RUNS" | jq "map(select(.databaseId == $PUSHED_JOBS_RUN_ID)) | .[0].name")
        echo
        echo "Viewing Failed Job Run for '$PUSHED_JOBS_RUN_NAME'"
        echo
        PAGER="" gh api /repos/${REMOTE_REPO}/actions/jobs/${PUSHED_JOBS_RUN_ID}/logs
    done
}

alias gh-pr-dp="viewPushedPRJobLogs"

alias gbrdf="git push origin --delete"

function makeGIF {
    local VIDEO=$1
    local FILENAME=$(basename $VIDEO)
    local DIRECTORY=$(dirname $VIDEO)
    ffmpeg -i $VIDEO -vf "fps=5,split[s0][s1];[s0]palettegen=max_colors=32[p];[s1][p]paletteuse,setpts=PTS/2" -loop -1 $DIRECTORY/${FILENAME%.*}.gif
}

function makeMP4 {
    local VIDEO=$1
    local FILENAME=$(basename $VIDEO)
    local DIRECTORY=$(dirname $VIDEO)
    ffmpeg -i $VIDEO -vf "setpts=PTS/3" -vcodec libx264 -crf 34 $DIRECTORY/${FILENAME%.*}-sm.mp4
}

alias sc="ffmpeg -f x11grab -video_size 2560x1440 -i $DISPLAY -vframes 1"
alias scr="ffmpeg -f x11grab -video_size 2560x1440 -framerate 25 -i $DISPLAY -c:v libx264 -preset ultrafast -c:a aac"
alias scr-gif="makeGIF"
alias scr-mp4="makeMP4"
